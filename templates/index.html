<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transcripci√≥n en Vivo - Soniox</title>
    <script src="https://cdn.socket.io/4.5.4/socket.io.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/lamejs@1.2.0/lame.min.js"></script>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üé§ Transcripci√≥n en Vivo</h1>
            <p>Powered by Soniox Speech-to-Text (Espa√±ol)</p>
        </div>

        <div class="main-card">
            <div class="tab-bar">
                <button class="tab-btn active" onclick="showTab('soniox')">Soniox STT</button>
                <button class="tab-btn" onclick="showTab('deepgram')">Deepgram AI</button>
            </div>

            <!-- SONIOX TAB (default) -->
            <div id="tab-soniox" class="tab-content" style="display:block;">

                <div id="statusBar" class="status connected">
                    <span id="statusText">Conectado al servidor</span>
                </div>
                <div id="errorBar" class="error" style="display: none;"></div>
                <div class="controls">
                    <button id="startBtn" class="btn btn-start" onclick="startRecording()">
                        üéôÔ∏è Iniciar Grabaci√≥n
                    </button>
                    <button id="stopBtn" class="btn btn-stop" onclick="stopRecording()" disabled>
                        ‚èπÔ∏è Detener
                    </button>
                    <button class="btn btn-clear" onclick="clearTranscription()">
                        üóëÔ∏è Limpiar
                    </button>
                </div>
                <div class="upload-area" id="uploadArea" onclick="document.getElementById('fileInput').click()">
                    <h3>üìÅ O arrastra un archivo de audio aqu√≠</h3>
                    <p>Soporta: MP3, WAV, OGG, WEBM, FLAC</p>
                    <input type="file" id="fileInput" accept="audio/*" onchange="handleFileUpload(this.files[0])">
                </div>
                <div id="loadingBar" class="loading">
                    <div class="spinner"></div>
                    <p>Transcribiendo...</p>
                </div>
                <div id="transcription" class="transcription-box"></div>
                <div class="stats">
                    <div class="stat-card">
                        <h3 id="wordCount">0</h3>
                        <p>Palabras</p>
                    </div>
                    <div class="stat-card">
                        <h3 id="charCount">0</h3>
                        <p>Caracteres</p>
                    </div>
                    <div class="stat-card">
                        <h3 id="duration">0s</h3>
                        <p>Duraci√≥n</p>
                    </div>
                </div>
            </div>

            <!-- DEEPGRAM TAB -->
            <div id="tab-deepgram" class="tab-content" style="display:none;">
                <div class="deepgram-section">
                    <h2 class="deepgram-title">Deepgram AI Speech-to-Text</h2>
                    <div class="controls">
                        <select id="dgLanguage" class="styled-input">
                            <option value="es" selected>Espa√±ol</option>
                            <option value="en">English</option>
                            <option value="pt">Portugu√™s</option>
                            <option value="fr">Fran√ßais</option>
                            <option value="de">Deutsch</option>
                            <option value="it">Italiano</option>
                        </select>
                    </div>
                    <div class="controls">
                        <input type="file" id="dgLocalFile" accept="audio/*" class="styled-input">
                        <button class="btn btn-start" onclick="deepgramLocalSTT()">Transcribir archivo local</button>
                    </div>
                    <div class="controls">
                        <input type="text" id="dgRemoteUrl" placeholder="URL de audio remoto" class="styled-input wide-input">
                        <button class="btn btn-start" onclick="deepgramRemoteSTT()">Transcribir URL remota</button>
                        <button class="btn btn-start" onclick="deepgramStreamingSTT()" id="startStreamingBtn">Streaming STT</button>
                        <button class="btn btn-stop" onclick="stopDeepgramStreaming()" id="stopStreamingBtn" disabled>Detener Streaming</button>
                    </div>

                    <div class="controls">
                        <textarea id="dgTtsText" rows="2" placeholder="Texto para sintetizar" class="styled-input wide-input"></textarea>
                        <select id="dgTtsModel" class="styled-input">
                            <option value="aura-asteria-en">aura-asteria-en</option>
                            <option value="aura-orion-en">aura-orion-en</option>
                            <option value="aura-2-celeste-es">aura-2-celeste-es</option>
                            <option value="aura-2-javier-es">aura-2-javier-es</option>
                        </select>
                        <select id="dgTtsEncoding" class="styled-input">
                            <option value="linear16">linear16</option>
                            <option value="mulaw">mulaw</option>
                            <option value="alaw">alaw</option>
                        </select>
                        <select id="dgTtsSampleRate" class="styled-input">
                            <option value="8000">8000</option>
                            <option value="16000">16000</option>
                            <option value="24000" selected>24000</option>
                            <option value="44100">44100</option>
                            <option value="48000">48000</option>
                        </select>
                        <select id="dgTtsMipOptOut" class="styled-input">
                            <option value="false">Mejora de modelo: No</option>
                            <option value="true">Mejora de modelo: S√≠</option>
                        </select>
                        <button class="btn btn-start" onclick="deepgramTTS()">Texto a voz</button>
                    </div>
                    <div id="dgResult" class="transcription-box"></div>
                    <audio id="dgAudio" controls style="width:100%;display:none;"></audio>
                </div>
            </div>

    <script>
        // Tab switching logic
        function showTab(tab) {
            document.querySelectorAll('.tab-btn').forEach(btn => btn.classList.remove('active'));
            document.querySelectorAll('.tab-content').forEach(tabDiv => tabDiv.style.display = 'none');
            document.querySelector('.tab-btn[onclick*="' + tab + '"]').classList.add('active');
            document.getElementById('tab-' + tab).style.display = 'block';
        }

    const socket = io();
    // --- Deepgram handlers ---
        async function deepgramLocalSTT() {
            const fileInput = document.getElementById('dgLocalFile');
            const resultDiv = document.getElementById('dgResult');
            const language = document.getElementById('dgLanguage').value;
            resultDiv.textContent = 'Procesando...';
            if (!fileInput.files.length) {
                resultDiv.textContent = 'Seleccione un archivo de audio.';
                return;
            }
            const formData = new FormData();
            formData.append('audio', fileInput.files[0]);
            formData.append('language', language);
            const resp = await fetch('/deepgram/local-stt', { method: 'POST', body: formData });
            const data = await resp.json();
            if (data.error) {
                resultDiv.textContent = 'Error: ' + data.error;
            } else {
                const alt = data.results?.channels?.[0]?.alternatives?.[0];
                resultDiv.textContent = alt?.transcript || JSON.stringify(data);
            }
        }

        async function deepgramRemoteSTT() {
            const url = document.getElementById('dgRemoteUrl').value;
            const resultDiv = document.getElementById('dgResult');
            const language = document.getElementById('dgLanguage').value;
            resultDiv.textContent = 'Procesando...';
            if (!url) {
                resultDiv.textContent = 'Ingrese una URL de audio.';
                return;
            }
            const resp = await fetch('/deepgram/remote-stt', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ url, language })
            });
            const data = await resp.json();
            if (data.error) {
                resultDiv.textContent = 'Error: ' + data.error;
            } else {
                const alt = data.results?.channels?.[0]?.alternatives?.[0];
                resultDiv.textContent = alt?.transcript || JSON.stringify(data);
            }
        }

        // --- Deepgram streaming STT handler ---

        let streamingActive = false;
        function deepgramStreamingSTT() {
            const url = document.getElementById('dgRemoteUrl').value;
            const resultDiv = document.getElementById('dgResult');
            resultDiv.textContent = '';
            if (!url) {
                resultDiv.textContent = 'Ingrese una URL de audio.';
                return;
            }
            streamingActive = true;
            document.getElementById('startStreamingBtn').disabled = true;
            document.getElementById('stopStreamingBtn').disabled = false;
            socket.emit('deepgram_streaming_stt', { url });
        }

        function stopDeepgramStreaming() {
            streamingActive = false;
            document.getElementById('startStreamingBtn').disabled = false;
            document.getElementById('stopStreamingBtn').disabled = true;
            socket.emit('deepgram_streaming_stop');
        }

        socket.on('deepgram_streaming_result', function(data) {
            const resultDiv = document.getElementById('dgResult');
            if (data.error) {
                resultDiv.textContent = 'Error: ' + data.error;
                stopDeepgramStreaming();
            } else if (data.transcript) {
                const span = document.createElement('span');
                span.className = 'word new';
                span.textContent = data.transcript + ' ';
                resultDiv.appendChild(span);
                setTimeout(() => { span.classList.remove('new'); }, 500);
                resultDiv.scrollTop = resultDiv.scrollHeight;
            } else if (data.done) {
                stopDeepgramStreaming();
            }
        });
        // Polyfill for EventSource with POST support
        // https://github.com/amvtek/EventSource
        function EventSourcePolyfill(url, options) {
            options = options || {};
            const xhr = new XMLHttpRequest();
            xhr.open('POST', url, true);
            if (options.headers) {
                for (const k in options.headers) xhr.setRequestHeader(k, options.headers[k]);
            }
            let listeners = {};
            xhr.onreadystatechange = function() {
                if (xhr.readyState === 3 || xhr.readyState === 4) {
                    const lines = xhr.responseText.split(/\n\n/);
                    for (let i = 0; i < lines.length; i++) {
                        const line = lines[i].trim();
                        if (line.startsWith('data:')) {
                            const data = line.replace('data:', '').trim();
                            if (listeners['message']) listeners['message']({ data });
                        }
                    }
                }
            };
            xhr.onerror = function() { if (listeners['error']) listeners['error'](); };
            xhr.send(options.payload || null);
            return {
                onmessage: function(cb) { listeners['message'] = cb; },
                onerror: function(cb) { listeners['error'] = cb; },
                close: function() { xhr.abort(); }
            };
        }

        async function deepgramTTS() {
            const text = document.getElementById('dgTtsText').value;
            const model = document.getElementById('dgTtsModel').value;
            const encoding = document.getElementById('dgTtsEncoding').value;
            const sample_rate = document.getElementById('dgTtsSampleRate').value;
            const mip_opt_out = document.getElementById('dgTtsMipOptOut').value;
            const resultDiv = document.getElementById('dgResult');
            const audioEl = document.getElementById('dgAudio');
            resultDiv.textContent = 'Procesando...';
            audioEl.style.display = 'none';
            if (!text) {
                resultDiv.textContent = 'Ingrese texto para sintetizar.';
                return;
            }
            const resp = await fetch('/deepgram/tts', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ text, model, encoding, sample_rate, mip_opt_out })
            });
            const data = await resp.json();
            if (data.error) {
                resultDiv.textContent = 'Error: ' + data.error;
            } else if (data.audio) {
                const audioSrc = 'data:audio/wav;base64,' + data.audio;
                audioEl.src = audioSrc;
                audioEl.style.display = 'block';
                resultDiv.textContent = 'Audio generado:';
            }
        }
        let mediaRecorder;
        let audioChunks = [];
        let startTime;
        let isRecording = false;
        let audioContext;
        let audioStream;

        // Elementos del DOM
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusBar = document.getElementById('statusBar');
        const statusText = document.getElementById('statusText');
        const transcriptionDiv = document.getElementById('transcription');
        const errorBar = document.getElementById('errorBar');
        const loadingBar = document.getElementById('loadingBar');
        const uploadArea = document.getElementById('uploadArea');

        // Socket.IO events
        socket.on('connect', () => {
            console.log('Conectado al servidor');
            updateStatus('Conectado al servidor', 'connected');
        });

        socket.on('disconnect', () => {
            console.log('Desconectado del servidor');
            updateStatus('Desconectado del servidor', 'stopped');
        });

        socket.on('status', (data) => {
            updateStatus(data.message, data.status);
        });

        socket.on('transcription', (data) => {
            addTranscription(data.text);
            updateStats();
        });

        socket.on('file_transcription', (data) => {
            loadingBar.style.display = 'none';
            transcriptionDiv.innerHTML = '';
            addTranscription(data.text);
            updateStats();
        });

        socket.on('error', (data) => {
            showError(data.message);
            loadingBar.style.display = 'none';
        });

        // Funciones de grabaci√≥n
        async function startRecording() {
            try {
                audioStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000
                    }
                });
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
                
                const source = audioContext.createMediaStreamSource(audioStream);
                const processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                let audioBuffer = [];
                const CHUNK_DURATION = 2000; // 2 segundos
                const SAMPLES_PER_CHUNK = 16000 * 2; // 16kHz * 2 segundos
                
                processor.onaudioprocess = (e) => {
                    if (!isRecording) return;
                    
                    const inputData = e.inputBuffer.getChannelData(0);
                    audioBuffer.push(...inputData);
                    
                    // Cuando tenemos suficientes samples, enviar
                    if (audioBuffer.length >= SAMPLES_PER_CHUNK) {
                        const chunk = audioBuffer.slice(0, SAMPLES_PER_CHUNK);
                        audioBuffer = audioBuffer.slice(SAMPLES_PER_CHUNK);
                        
                        // Convertir a WAV
                        const wavBlob = encodeWAV(chunk, 16000);
                        const reader = new FileReader();
                        reader.onload = () => {
                            const base64Audio = reader.result.split(',')[1];
                            socket.emit('audio_chunk', {
                                audio: base64Audio,
                                timestamp: Date.now() - startTime
                            });
                        };
                        reader.readAsDataURL(wavBlob);
                    }
                };
                
                source.connect(processor);
                processor.connect(audioContext.destination);

                audioChunks = [];
                startTime = Date.now();

                isRecording = true;
                startBtn.disabled = true;
                stopBtn.disabled = false;
                
                socket.emit('start_recording');
                updateStatus('Grabando...', 'recording');
                updateDuration();

            } catch (err) {
                showError('Error al acceder al micr√≥fono: ' + err.message);
            }
        }

        function stopRecording() {
            if (isRecording) {
                isRecording = false;
                
                if (audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                }
                if (audioContext) {
                    audioContext.close();
                }
                
                startBtn.disabled = false;
                stopBtn.disabled = true;
                
                socket.emit('stop_recording');
                updateStatus('Grabaci√≥n detenida', 'stopped');
            }
        }
        
        // Funci√≥n para convertir Float32Array a WAV
        function encodeWAV(samples, sampleRate) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);
            
            // WAV header
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + samples.length * 2, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true); // fmt chunk size
            view.setUint16(20, 1, true); // PCM format
            view.setUint16(22, 1, true); // mono
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true); // byte rate
            view.setUint16(32, 2, true); // block align
            view.setUint16(34, 16, true); // bits per sample
            writeString(view, 36, 'data');
            view.setUint32(40, samples.length * 2, true);
            
            // PCM samples
            let offset = 44;
            for (let i = 0; i < samples.length; i++, offset += 2) {
                const s = Math.max(-1, Math.min(1, samples[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
            
            return new Blob([buffer], { type: 'audio/wav' });
        }
        
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        function clearTranscription() {
            transcriptionDiv.innerHTML = '';
            updateStats();
        }

        // Manejo de archivos
        function handleFileUpload(file) {
            if (!file) return;

            loadingBar.style.display = 'block';
            transcriptionDiv.innerHTML = '';

            const reader = new FileReader();
            reader.onload = () => {
                const base64Audio = reader.result.split(',')[1];
                const format = file.type.split('/')[1] || 'webm';
                
                socket.emit('transcribe_file', {
                    audio: base64Audio,
                    format: format
                });
            };
            reader.readAsDataURL(file);
        }

        // Drag and drop
        uploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadArea.classList.add('dragover');
        });

        uploadArea.addEventListener('dragleave', () => {
            uploadArea.classList.remove('dragover');
        });

        uploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadArea.classList.remove('dragover');
            const file = e.dataTransfer.files[0];
            handleFileUpload(file);
        });

        // Funciones auxiliares
        function updateStatus(message, status) {
            statusText.textContent = message;
            statusBar.className = 'status ' + status;
        }

        function addTranscription(text) {
            const words = text.split(' ');
            words.forEach(word => {
                const span = document.createElement('span');
                span.className = 'word new';
                span.textContent = word + ' ';
                
                if (word.trim() === '') return;
                transcriptionDiv.appendChild(span);
                
                setTimeout(() => {
                    span.classList.remove('new');
                }, 500);
            });
            
            transcriptionDiv.scrollTop = transcriptionDiv.scrollHeight;
        }

        function updateStats() {
            const text = transcriptionDiv.textContent.trim();
            const words = text ? text.split(/\s+/).length : 0;
            const chars = text.length;
            
            document.getElementById('wordCount').textContent = words;
            document.getElementById('charCount').textContent = chars;
        }

        function updateDuration() {
            if (isRecording) {
                const elapsed = Math.floor((Date.now() - startTime) / 1000);
                document.getElementById('duration').textContent = elapsed + 's';
                setTimeout(updateDuration, 1000);
            }
        }

        function showError(message) {
            errorBar.textContent = '‚ùå ' + message;
            errorBar.style.display = 'block';
            setTimeout(() => {
                errorBar.style.display = 'none';
            }, 5000);
        }
    </script>
</body>
</html>
